# Advanced Dimensionality Reduction

Below are the additional materials I covered when learning the concept:

---

## [Visualising High-Dimensional Space](https://www.youtube.com/watch?v=wvsE8jm1GzE&ab_channel=GoogleforDevelopers)

This Google Developers experiment helps visualise what’s happening in machine learning. It allows coders to see and explore their high-dimensional data.

---

## [Experiments with Google: Infinite Drum Machine](https://experiments.withgoogle.com/drum-machine)

Sounds are complex and vary widely. This experiment uses machine learning to organise thousands of everyday sounds. The computer wasn’t given any descriptions or tags – only the audio. Using a technique called t-SNE, the computer placed similar sounds closer together. You can use the map to explore neighbourhoods of similar sounds and even make beats using the drum sequencer.

---

## [Embedding Projector - Visualising High-Dimensional Space](https://projector.tensorflow.org/)

This interactive clustering experiment lets you choose different dimensionality reduction techniques and hyperparameters to visualise found relationships in words.

---

## [In Depth: Manifold Learning](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.10-Manifold-Learning.ipynb)

A look at nonlinear dimensionality reduction techniques like Multidimensional Scaling, Locally Linear Embedding, and Isomaps.

---

## [How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/)

Although extremely useful for visualising high-dimensional data, t-SNE plots can sometimes be mysterious or misleading. By exploring how it behaves in simple cases, we can learn to use it more effectively.

---

## [StatQuest: t-SNE, Clearly Explained](https://www.youtube.com/watch?v=NEaUSP4YerM&ab_channel=StatQuestwithJoshStarmer)

A StatQuest video on t-SNE, a popular method for making an easy to read graph from a complex dataset.

---