---

# Resources on: Classification Metrics

This reference document is designed to enhance your understanding of binary classification metrics. It includes a variety of resources to help you evaluate the performance of binary classification models using different metrics. The goal is to provide you with a comprehensive toolkit to make informed decisions when assessing model performance..

## References

### Articles

- **[Metrics to evaluate your classification model](https://www.analyticsvidhya.com/blog/2021/07/metrics-to-evaluate-your-classification-model-to-take-the-right-decisions/)**: An overview of essential metrics for assessing the performance of binary classification models and the importance of choosing a suitable one.
- **[Metrics to consider when evaluating a binary classification model](https://www.pi.exchange/knowledgehub/metrics-to-consider-when-evaluating-a-binary-classification-models-performance)**: A comprehensive guide on which metrics to consider when evaluating a binary classification model.
- **[Useful metrics to evaluate binary classification models](https://thedigitalskye.com/2021/04/19/6-useful-metrics-to-evaluate-binary-classification-models/)**: An informative article covering various metrics to evaluate binary classification models effectively.

### Video Lessons

- **[ROC curves and Area Under the Curve explained](https://www.dataschool.io/roc-curves-and-auc-explained/)**: A video lesson to help you gain an intuitive understanding of ROC curves and Area Under the Curve.

### Articles with Implementations

- **[How to evaluate classification models in Python](https://builtin.com/data-science/evaluating-classification-models)**: An article that covers and implements classification performance metrics in Python.

### Official Documentation

- **[Scikit-learn's model evaluation documentation](https://scikit-learn.org/stable/modules/model_evaluation.html)**: The official documentation for model evaluation in Scikit-learn, offering a deep dive into the metrics and tools available within the library for assessing model performance.

---
